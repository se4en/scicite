{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa9933b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec3369f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa18936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aea2a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_text = \"A further complication is that different speakers can regard very different values as prototypical , making it difficult to assess which of two objects is greener even on one dimension ( Berlin and Kay 1969 , pages 10 -- 12 ) .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1747619",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70ae26b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertTokenizerFast' object has no attribute 'token_indexers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14366/4234714424.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'BertTokenizerFast' object has no attribute 'token_indexers'"
     ]
    }
   ],
   "source": [
    "tokenizer.token_indexers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce45edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_tok = tokenizer.encode(ex_text, padding='max_length', max_length=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef00cfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[102,\n",
       " 106,\n",
       " 911,\n",
       " 11100,\n",
       " 165,\n",
       " 198,\n",
       " 643,\n",
       " 13262,\n",
       " 300,\n",
       " 1985,\n",
       " 1248,\n",
       " 643,\n",
       " 988,\n",
       " 188,\n",
       " 12473,\n",
       " 7276,\n",
       " 281,\n",
       " 422,\n",
       " 3469,\n",
       " 256,\n",
       " 2537,\n",
       " 147,\n",
       " 1285,\n",
       " 334,\n",
       " 131,\n",
       " 502,\n",
       " 3200,\n",
       " 165,\n",
       " 3755,\n",
       " 114,\n",
       " 1390,\n",
       " 191,\n",
       " 482,\n",
       " 2334,\n",
       " 145,\n",
       " 11178,\n",
       " 137,\n",
       " 21524,\n",
       " 4798,\n",
       " 30141,\n",
       " 422,\n",
       " 5873,\n",
       " 566,\n",
       " 579,\n",
       " 579,\n",
       " 760,\n",
       " 546,\n",
       " 205,\n",
       " 103,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5d9957a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7876034",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_tok_torch = torch.tensor(after_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c5df4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_tok_torch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21e3bfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_tok_torch_new = after_tok_torch.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0b064a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_tok_torch_new.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0564de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbert = model(after_tok_torch_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c448c58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbert[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99baf7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d5d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e1e605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2218b3555946f7905865305fa71a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea8e00301624da39736645a2c64e9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/228k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fb06ad488d4391968d1137f3bf32b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf0e28b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_text = \"A further complication is that different speakers can regard very different values as prototypical , making it difficult to assess which of two objects is greener even on one dimension ( Berlin and Kay 1969 , pages 10 -- 12 ) .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e7ca893",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"ex_text\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e176897e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [102, 199, 4627, 3267, 103], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c7724b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daedbc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = res.last_hidden_state\n",
    "outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56826566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.1531e-01,  4.6779e-01,  4.8340e-02, -9.0617e-01,  4.2295e-01,\n",
       "         -4.6507e-02,  9.0466e-01,  2.9243e-01,  6.1486e-02,  5.0551e-01,\n",
       "          1.0349e+00, -9.7596e-01, -4.0948e-01, -5.6100e-01,  4.2165e-01,\n",
       "          4.2289e-01, -1.7266e-01,  3.9593e-01, -1.8149e-01, -7.4578e-01,\n",
       "          8.9677e-01,  2.6836e-01,  4.6878e-02, -6.2918e-01, -3.5193e-02,\n",
       "          7.5716e-01,  5.9197e-02,  1.5945e-01, -5.4270e-01,  1.6704e+00,\n",
       "         -8.6749e-01, -8.8158e-01, -8.8664e-01, -1.1114e+00, -5.1723e-01,\n",
       "         -1.9641e+00, -5.2980e-02, -4.2749e-03, -1.4160e+00,  5.7298e-01,\n",
       "          4.4526e-01,  2.6446e-01,  1.2362e+00,  4.2917e-01,  6.8873e-01,\n",
       "          1.0907e-01,  7.2299e-01,  4.5659e-01,  9.9713e-01,  7.9990e-01,\n",
       "         -8.8173e-01, -7.2778e-01,  1.4722e-01,  1.0412e+00,  2.4549e-01,\n",
       "         -5.7653e-01, -8.8783e-03, -6.3002e-01,  1.7473e-02, -3.7978e-01,\n",
       "         -3.6864e-01, -2.2619e-01, -2.2743e-01,  3.2840e-02, -6.7003e-02,\n",
       "          2.5882e-01, -5.2647e-01,  5.6615e-02,  2.2746e+00,  3.1476e-01,\n",
       "          7.9391e-01,  6.3008e-01,  4.7630e-02,  1.3493e-01, -1.2255e+00,\n",
       "          5.6277e-01, -4.9111e-01, -1.4404e-01, -9.8960e-01,  5.6054e-01,\n",
       "         -5.5801e-01, -1.5888e+00,  5.3349e-02,  1.1039e+00, -8.1690e-01,\n",
       "          3.3380e-01, -9.7192e-01, -8.4961e-01, -1.1097e+00, -3.2507e-02,\n",
       "          1.0256e+00,  4.3553e-01,  8.0064e-01,  4.0247e-01,  9.9634e-02,\n",
       "         -4.7387e-01,  3.0857e-01, -1.7621e-02,  8.6447e-01,  1.4041e+00,\n",
       "          5.6230e-01,  6.1678e-01, -1.1628e-02, -2.5457e-02,  9.4304e-01,\n",
       "          6.1099e-01, -2.8496e-01, -9.1529e-01,  6.6001e-01,  1.2513e+00,\n",
       "         -1.7846e-01, -1.0421e+00, -2.2516e-01, -3.7296e-01, -9.5743e-01,\n",
       "          1.3036e-01, -1.4639e+00, -1.5267e+00, -2.8216e-01,  1.2911e+00,\n",
       "         -3.4847e-01, -1.0872e+00,  2.2051e-01, -7.1779e-01,  8.4818e-01,\n",
       "          1.2762e+00,  4.5708e-01, -5.3275e-01, -5.7421e-01, -2.5572e-01,\n",
       "         -5.2008e-01,  4.3654e-01,  9.9962e-01, -7.1462e-01, -2.9325e-01,\n",
       "         -3.5128e-01, -7.4748e-01, -2.1895e-01,  1.1411e-01, -5.7707e-01,\n",
       "         -1.3882e+00, -4.3942e-01,  6.0801e-01, -1.6009e-01,  1.9126e-01,\n",
       "          2.8033e-01,  5.1841e-01,  2.0361e-02, -6.9540e-01, -1.8787e-01,\n",
       "         -7.0253e-01,  1.1568e-03, -3.4159e-01, -2.8348e-01,  3.5022e-03,\n",
       "         -2.3375e-01,  1.7359e-01, -7.6592e-01, -1.1470e+00,  1.1199e-02,\n",
       "         -7.2221e-01, -2.8877e-01, -4.1159e-02,  8.2295e-01, -4.1703e-01,\n",
       "          2.4490e-02,  1.4062e-01,  9.0056e-01,  5.7590e-01,  9.8767e-01,\n",
       "         -1.0237e+00, -1.1509e-01,  2.2272e-01,  2.4338e+00,  9.6603e-01,\n",
       "          2.7012e-01, -1.0939e+00,  4.6559e-02,  4.1275e-01,  8.4668e-01,\n",
       "         -1.0756e+00, -2.3235e-01, -1.2750e-01, -1.1243e+00, -4.4797e-02,\n",
       "         -2.8470e-01,  8.1369e-01,  6.2921e-01, -4.4413e-01,  1.5073e-01,\n",
       "          2.3479e+00, -3.6128e-01,  8.4917e-01, -6.4564e-01, -5.8738e-01,\n",
       "         -5.5726e-01, -8.6369e-01, -5.3866e-01, -5.6778e-01,  7.1542e-01,\n",
       "         -1.9853e-01, -7.7813e-02,  7.2445e-02, -3.0580e-01,  3.5964e-03,\n",
       "         -6.9776e-01, -1.6284e-01, -1.2966e-01,  2.0741e-01, -3.1970e-01,\n",
       "          1.0220e+00, -7.5570e-01, -1.0321e-02,  2.7176e-01, -3.4984e-01,\n",
       "         -3.3820e-01,  6.2538e-01,  4.5057e-01, -1.4361e+00, -5.1235e-01,\n",
       "         -2.7905e-01,  2.6757e-01, -4.3763e-01,  1.0225e+00,  7.8213e-01,\n",
       "          7.8937e-01, -1.0307e+00,  5.3536e-01,  6.6149e-01,  4.9101e-01,\n",
       "          1.1223e+00,  1.4198e-01,  2.3083e-01, -4.7340e-01,  6.7293e-01,\n",
       "         -2.8479e-02,  1.1895e-01, -1.1852e+00, -3.4144e-01, -3.1456e-01,\n",
       "          3.9048e-01,  8.0964e-01, -3.4818e-01,  9.3565e-02, -2.9914e-01,\n",
       "         -7.8389e-01, -5.8095e-01,  1.9333e-01,  1.4730e+00,  5.6491e-01,\n",
       "          1.1950e-01,  1.4721e-01, -2.9579e-01, -4.2074e-01, -2.9973e-04,\n",
       "          5.3672e-01,  7.3606e-01, -2.1588e-01, -2.8440e-01, -4.7686e-01,\n",
       "         -3.2681e-01,  3.1629e-01, -9.1539e-02,  1.7711e+00, -1.3109e-01,\n",
       "         -2.6205e-01,  2.9423e-02, -2.2104e-01, -5.0428e-01, -2.8397e-01,\n",
       "         -8.6788e-01, -4.0341e-01,  1.6678e-01,  2.8121e-01,  4.5343e-01,\n",
       "          6.3197e-01,  6.1437e-01, -6.1666e-01,  7.1598e-01, -3.1419e-01,\n",
       "         -4.9398e-01, -2.0798e-01, -4.3467e-01,  7.9915e-01, -1.0444e+00,\n",
       "         -7.0258e-01,  1.7546e-01,  1.8041e-01,  8.5666e-01, -1.4754e+00,\n",
       "         -1.3419e-01, -2.5687e-01,  5.0055e-01,  4.5007e-01, -1.4718e-01,\n",
       "         -5.4110e-01, -4.2296e-01,  3.6970e-01, -1.8036e-01,  8.1035e-03,\n",
       "         -2.3100e-01,  6.0155e-01, -8.0504e-01,  9.2922e-03, -2.9056e-01,\n",
       "         -1.8353e-01,  7.8629e-01,  1.0861e+00,  1.2340e-01,  5.2068e-01,\n",
       "         -1.3515e-01, -1.1988e-01, -1.3865e-01, -2.6060e-01, -6.4290e-01,\n",
       "         -4.2191e-01, -8.6740e-01,  8.9503e-01,  2.9525e-01,  3.6552e-01,\n",
       "          1.8279e-01, -5.1356e-01, -1.1626e+00,  4.7965e-01, -1.7338e-01,\n",
       "          6.9042e-01,  1.6382e-01, -1.8424e-01,  2.9856e-02, -1.0370e-01,\n",
       "          3.2998e-02,  1.3700e-01, -3.2937e-01,  4.7278e-01,  5.0610e-01,\n",
       "         -5.6587e-01,  3.2673e-01, -3.9090e-01,  6.9756e-01, -4.6074e-01,\n",
       "         -6.9938e-01,  4.8838e-01, -9.8402e-02,  4.0052e-01,  1.3624e+00,\n",
       "         -5.2678e-01, -8.0675e-01, -4.6501e-01,  6.8609e-01, -1.3172e+00,\n",
       "         -5.1559e-01, -4.0896e-01,  6.2625e-01,  1.6058e-01, -7.9155e-01,\n",
       "          6.9538e-01, -1.7390e-01,  3.9923e-02,  1.2015e+00,  1.4402e+00,\n",
       "         -8.2422e-01, -1.1326e+00, -1.0092e+00,  3.0702e-01,  6.3889e-01,\n",
       "         -4.9917e-01,  1.5445e-01, -2.9651e-01,  5.5916e-01, -4.1744e-01,\n",
       "         -7.4658e-01, -1.4506e+00, -2.8526e-01,  4.4341e-02,  1.5346e-02,\n",
       "          1.2939e-01,  7.1890e-02, -2.7611e-01, -4.0999e-01, -2.4688e-01,\n",
       "          6.5705e-01,  3.1847e-01, -4.7876e-01, -3.9218e-01,  1.9311e-01,\n",
       "         -1.6373e-01,  3.9461e-01,  7.8241e-01,  4.9986e-01,  6.1347e-01,\n",
       "          5.2802e-01,  3.4179e-01, -9.8183e-01,  3.1412e-01,  6.1367e-01,\n",
       "         -6.6364e-02,  8.2106e-01, -5.4353e-01,  6.6080e-01,  3.5589e-01,\n",
       "          1.0063e+00, -3.3598e-01, -8.3856e-01, -7.4002e-01,  4.2274e-01,\n",
       "         -7.8597e-01, -1.9465e-01,  9.3828e-01,  6.1931e-01,  7.3333e-01,\n",
       "          5.2995e-01, -5.0657e-01, -8.4084e-01,  6.6871e-01, -4.4166e-01,\n",
       "          1.2306e-01,  5.3898e-02,  1.4127e-01,  6.3456e-02, -1.1633e-01,\n",
       "         -7.3643e-02, -1.5588e-01,  1.3759e+01,  6.2163e-01, -1.8143e+00,\n",
       "         -1.0124e+00, -5.5668e-01,  2.4617e-01, -3.5584e-01, -4.5500e-03,\n",
       "         -7.8349e-01,  4.7754e-01,  1.2472e+00, -4.7924e-01,  7.8670e-01,\n",
       "         -6.5416e-02,  1.0034e+00, -1.2189e+00, -1.6076e-01, -5.7627e-01,\n",
       "          2.0909e-01, -3.0100e-01,  5.3845e-01,  9.1774e-01, -4.8285e-01,\n",
       "          4.2485e-01,  1.0703e-01,  7.2750e-01, -6.6709e-01, -9.4178e-01,\n",
       "          1.9739e-01, -7.2356e-01,  1.0488e+00,  1.1533e+00,  2.8616e-01,\n",
       "         -5.0158e-02, -3.7366e-01, -1.2307e+00,  4.6380e-01, -4.3070e-01,\n",
       "         -6.5378e-01, -5.0881e-01, -7.8065e-01,  9.9372e-01, -1.0665e+00,\n",
       "          3.8001e-01, -1.5694e+00, -5.5638e-02,  3.4589e-01,  1.7256e+00,\n",
       "          1.9109e-01, -7.8967e-01, -8.2177e-02,  1.2972e+00,  6.4097e-01,\n",
       "          5.2992e-01, -2.9319e-01,  7.4494e-01, -1.7702e-03,  4.1860e-01,\n",
       "         -1.0240e-01,  3.3892e-01,  6.8063e-03, -5.9903e-01, -4.9601e-01,\n",
       "          1.0465e+00, -7.0607e-01,  1.0074e-01, -2.7011e-02, -3.1260e-01,\n",
       "         -5.3305e-01, -4.9656e-01,  5.4002e-01, -4.4032e-01, -6.9600e-01,\n",
       "          5.8742e-02, -2.0810e-01, -6.1564e-02, -7.3712e-01,  3.5267e-02,\n",
       "         -6.1624e-01,  5.8456e-01,  1.6830e-01, -1.5285e+00, -1.2778e-01,\n",
       "         -3.9621e-01,  7.6504e-03, -1.2288e+00,  1.0703e-01, -8.5108e-01,\n",
       "          1.1659e-01, -2.0785e-01,  1.0711e+00, -3.6604e-01, -4.6574e-01,\n",
       "          6.3363e-01,  1.8050e-01, -1.0729e+00,  4.0844e-01, -6.4041e-01,\n",
       "         -2.5627e-01,  4.4708e-01,  6.0927e-01,  1.2186e+00,  3.0965e-01,\n",
       "         -5.1217e-02,  4.5678e-01,  2.4033e-01, -1.1069e+00,  3.2920e-01,\n",
       "          5.3146e-01, -4.2107e-01, -7.3380e-01, -1.0192e-01, -1.9376e-01,\n",
       "          1.5585e-01,  3.8530e-02, -1.8264e-01,  6.4361e-01,  2.3043e-01,\n",
       "          4.6384e-02,  2.6393e-01,  1.1576e-01,  5.0991e-01, -6.7975e-02,\n",
       "         -1.6241e-01, -5.5857e-01,  4.5830e-02,  4.0169e-01, -2.4349e-01,\n",
       "         -6.9542e-01, -4.3808e-01,  4.5942e-01, -8.4978e-01, -8.1814e-01,\n",
       "         -9.9017e-03, -3.8928e-01,  8.1656e-01, -8.0648e-01,  4.5048e-01,\n",
       "          3.3083e-01,  2.3040e-02, -4.9927e-01,  1.8776e-01, -2.7138e-01,\n",
       "         -1.3403e+00,  7.0708e-01,  9.6527e-01, -3.0218e-01, -5.7876e-01,\n",
       "          3.2230e-01, -5.2929e-01, -3.3506e-01, -7.6379e-01, -1.0955e+00,\n",
       "          5.3761e-01,  1.1769e+00,  6.6877e-01,  7.3174e-02,  9.9186e-01,\n",
       "          1.4208e-01,  3.5078e-01,  7.6949e-01, -5.0801e-01, -2.9252e-01,\n",
       "          4.2397e-02,  1.0231e-02, -6.4267e-01,  6.5851e-02, -7.7118e-02,\n",
       "          7.6160e-01, -1.4960e+00,  1.6729e-01, -2.2240e-01, -1.0766e+00,\n",
       "         -1.6507e+00, -6.3810e-01, -3.6712e-01,  1.2170e+00,  7.6572e-01,\n",
       "         -5.2665e-02, -2.5012e-01, -5.5567e-01,  4.4264e-01,  4.3384e-02,\n",
       "          1.6794e-01,  1.5122e+00,  1.2413e-01,  2.5272e-01,  1.7962e-01,\n",
       "         -5.5100e-01, -5.7792e-01,  6.4384e-01, -4.9812e-01,  4.5807e-01,\n",
       "         -4.4725e-01,  1.0525e+00,  3.8857e-01, -5.9021e-02,  2.5367e-01,\n",
       "          4.3216e-01, -2.3012e-01,  1.0551e+00, -5.4585e-01,  6.8333e-01,\n",
       "          8.1376e-01, -7.1169e-01, -3.5227e-01, -2.0063e-01,  1.2573e+00,\n",
       "          4.8473e-01,  2.0528e-01, -2.9797e-03, -8.3812e-02, -6.0616e-01,\n",
       "          7.9637e-02, -2.1477e-01, -5.2115e-01, -2.5506e+00,  4.4685e-01,\n",
       "         -6.7654e-01, -1.3474e+00, -1.0110e+00, -2.8759e-01, -2.7321e-01,\n",
       "          5.2277e-01, -1.0478e-02,  9.6619e-01, -8.5645e-01, -2.5118e-01,\n",
       "          5.9408e-01,  6.7657e-01,  4.4986e-01, -3.0086e-01,  4.9243e-01,\n",
       "         -2.4931e-01, -6.5984e-01,  9.5055e-01,  3.2113e-01,  4.9838e-01,\n",
       "         -2.9945e-02,  5.6902e-02,  5.8101e-01,  1.1201e+00, -3.6482e-01,\n",
       "         -7.8995e-02, -1.0050e+00,  3.8730e-02,  8.9337e-01,  5.5948e-01,\n",
       "         -6.7349e-01, -2.3936e-01, -7.6329e-01,  1.4205e-02,  5.3592e-01,\n",
       "         -4.0349e-01,  4.2778e-01, -7.2954e-01,  1.9966e-01, -1.8724e-01,\n",
       "          1.0814e+00,  1.4153e-01,  6.2191e-01, -2.9565e-01, -3.0202e-01,\n",
       "          4.3214e-01, -1.4040e-01,  1.5100e+00, -3.2855e-01,  1.3907e+00,\n",
       "         -2.4311e-01, -1.3749e+00,  5.9954e-01,  3.4400e-01,  1.2607e+00,\n",
       "          1.2230e-01,  1.2543e+00, -2.9761e-01, -4.2645e-01,  2.2883e-01,\n",
       "         -4.2016e-01, -6.2067e-01, -4.0335e-01,  9.6126e-01, -3.7793e-01,\n",
       "         -1.9187e-01,  8.9019e-01, -2.8098e-01,  1.0809e+00, -6.9117e-01,\n",
       "         -4.6113e-01,  1.3443e+00,  1.0034e+00, -5.0486e-02, -4.1552e-01,\n",
       "         -1.7421e-01,  1.5155e-01,  1.1191e+00, -7.6081e-01, -4.8347e-01,\n",
       "         -6.2179e-02, -2.7801e-01, -1.9529e-01, -5.5091e-01, -4.0078e-01,\n",
       "         -8.5858e-01,  8.2996e-01,  5.7045e-01,  8.4253e-01, -1.2990e+00,\n",
       "         -4.3309e-02,  5.6258e-01, -1.0684e+00,  7.0293e-02, -2.6860e-01,\n",
       "          1.6645e-01, -1.8632e-01,  1.1843e+00, -1.1345e-01, -4.2265e-01,\n",
       "         -3.1869e-01,  6.8787e-01,  4.6996e-01, -4.5985e-01, -7.7873e-01,\n",
       "         -8.0202e-02,  5.8620e-01,  7.2763e-01, -1.6084e-01, -1.2759e+00,\n",
       "         -1.0127e+00, -2.2166e+00,  1.9580e-02, -3.3737e-01, -1.9891e-01,\n",
       "          1.2458e+00,  1.0996e+00,  1.0895e-01,  2.3165e-01, -4.5763e-01,\n",
       "          4.6375e-01, -4.0799e-01, -4.6433e-01, -1.1144e-01, -8.7737e-01,\n",
       "          2.6131e-01, -6.1229e-01, -8.3151e-01]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:, 3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af156533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
